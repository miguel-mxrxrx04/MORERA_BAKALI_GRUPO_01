{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracción de información. Deberás implementar varias funciones que, recibiendo como \n",
    "entrada un string (un post), devuelvan una lista con los resultados obtenidos. \n",
    " \n",
    "- find_subreddit_mentions(text: str):Permitirá extraer los subreddits mencionados en \n",
    "un post. Por ejemplo: “'I\\'m cross posting this from /r/cyberlaw, hopefully you guys find it \n",
    "as interesting”. Se debe extraer en este caso /r/cyberlaw. En caso de que haya más de uno, \n",
    "se deberán extraer todos y guardarlos en una lista. Para ello, se deberá utiliza una única \n",
    "expresión regular. \n",
    "- url_extraction(text: str) à Permitirá extraer todas las URLs en un post mediante una única \n",
    "expresión regular \n",
    "- phone_number_extracion(text: str): à Permitirá la extracción de números de teléfono \n",
    "mediante una única expresión regular \n",
    "- dates_extraction(text: str): à Permitirá la extracción de todas las fechas contenidas en un \n",
    "post. \n",
    "- code_extraction(text:str): Extracción de código de programación o HTML incluido en un \n",
    "post. Permitirá la extracción de todo el código que se incluya en un post. \n",
    "\n",
    "Todas  las  funciones  estarán  explicadas  y  detalladas  en  el  notebook  correspondiente, \n",
    "incluyendo su implementación final en 5 nuevas funciones en el archivo core.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Patrones 're' y desarrollo de código</h3>\n",
    "\n",
    "- Teniendo en cuenta que ya se ha debido eliminar tanto url's, números de teléfono, fechas, código HTML o menciones a subreddit para la adición de la columna 'post', gran parte del código será reutilizado aunque parcialmente modificado (centrarse en retornar 'matches' más que en eliminarlos).\n",
    "\n",
    "- Para la extracción del patrón de subreddit nos atenemos a las normas de construcción permitidas para los nombres\n",
    "```def find_subreddit_mentions(text: str)```\n",
    "\n",
    "- Para la extracción de números de teléfono tomamos en cuenta las siguientes posibilidades, procurando abarcar las máximas posibilidades: \n",
    "```\n",
    "telefonos: [\n",
    "    \"Contacta al 123-456-7890 para más información.\",\n",
    "    \"Nuestro número es (098) 765-4321.\",\n",
    "    \"Llámanos al +1 234 567 8901 o al 345.678.9012.\",\n",
    "    \"Número internacional: +44 20 7946 0958.\"\n",
    "    \"De 3 en 3 dígitos sin prefijo: 654 321 890.\"\n",
    "]\n",
    "phone_number_pattern = re.compile(\n",
    "    r'(\\+?\\d{1,3}[-.\\s]?)?'      # Prefijo\n",
    "    r'(\\(?\\d{3}\\)?[-.\\s]?)?'     # Código de área \n",
    "    r'(\\d{3}[-.\\s]?\\d{4})'       # Número de teléfono principal\n",
    "    r'|(\\+?\\d{1,3}[-.\\s]?)?'     # Prefijo internacional opcional 3 dígitos\n",
    "    r'(\\d{3}[-.\\s]\\d{3}[-.\\s]\\d{3})'  # Formato tipo \"654 231 235\"\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import re\n",
    "\n",
    "def find_subreddit_mentions(text: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Extrae menciones a subreddits del texto.\n",
    "\n",
    "    Parámetros:\n",
    "    - text (str): Texto del cual se extraerán las menciones a subreddits.\n",
    "\n",
    "    Retorna:\n",
    "    - List[str]: Lista de menciones de subreddits encontradas.\n",
    "    \"\"\"\n",
    "    # Patrón regex para menciones a subreddits (e.g., /r/Python)\n",
    "    subreddit_mention_pattern = re.compile(r'/r/[A-Za-z]{1}[A-Za-z0-9]{2,22}')\n",
    "    subreddit_mentions = subreddit_mention_pattern.findall(text)\n",
    "    return subreddit_mentions\n",
    "\n",
    "def url_extraction(text: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Extrae URLs del texto\n",
    "    \"\"\"\n",
    "    url_pattern = re.compile(\n",
    "        r'(https?://(?:www\\.|(?!www))[^\\s]+)|'      # URLs con http:// o https://\n",
    "        r'(www\\.[^\\s]+)|'                           # URLs que empiezan con www.\n",
    "        r'([a-zA-Z0-9.-]+\\.[a-zA-Z]{2,})'          # URLs sin protocolo\n",
    "    )\n",
    "    # Corregimos el orden: primero va el patrón, luego el texto\n",
    "    urls = re.findall(url_pattern, text)\n",
    "    \n",
    "    # Como findall con grupos retorna tuplas, necesitamos procesar el resultado\n",
    "    # para obtener solo las URLs válidas\n",
    "    extracted_urls = []\n",
    "    for url_tuple in urls:\n",
    "        # Tomar la primera URL no vacía de cada tupla\n",
    "        url = next((u for u in url_tuple if u), None)\n",
    "        if url:\n",
    "            extracted_urls.append(url)\n",
    "    \n",
    "    return extracted_urls\n",
    "\n",
    "def phone_number_extraction(text: str) -> List[str]|str:\n",
    "    \"\"\"\n",
    "    Extrae números de teléfono del texto, incluyendo formatos estándar y grupos de 3 dígitos.\n",
    "\n",
    "    Parámetros:\n",
    "    - text (str): Texto del cual se extraerán los números de teléfono.\n",
    "\n",
    "    Retorna:\n",
    "    - List[str]: Lista de números de teléfono encontrados.\n",
    "    \"\"\"\n",
    "    # Definir el patrón regex sin grupos de captura internos\n",
    "    phone_number_pattern = re.compile(\n",
    "        r'(?:\\+?\\d{1,3}[-.\\s]?)?'      # Prefijo internacional opcional\n",
    "        r'(?:\\(?\\d{3}\\)?[-.\\s]?)?'     # Código de área opcional con o sin paréntesis\n",
    "        r'\\d{3}[-.\\s]?\\d{4}'            # Número de teléfono principal\n",
    "        r'|'                            # Alternativa\n",
    "        r'(?:\\+?\\d{1,3}[-.\\s]?)?'      # Prefijo internacional opcional para formatos alternativos\n",
    "        r'\\d{3}[-.\\s]\\d{3}[-.\\s]\\d{3}'  # Formato tipo \"654 231 235\"\n",
    "    )\n",
    "    phone_numbers = phone_number_pattern.findall(text)\n",
    "    return [number.strip() for number in phone_numbers if number.strip()]\n",
    "\n",
    "def dates_extraction(text: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Extrae todas las fechas del texto en diferentes formatos utilizando una expresión regular.\n",
    "\n",
    "    Parámetros:\n",
    "    - text (str): Texto del cual se extraerán las fechas.\n",
    "\n",
    "    Retorna:\n",
    "    - List[str]: Lista de fechas encontradas.\n",
    "    \"\"\"\n",
    "    # Definir el patrón regex para extraer fechas en varios formatos\n",
    "    dates_pattern = re.compile(\n",
    "        r'(?<!\\w)'  # Asegura que la fecha no esté precedida por una letra\n",
    "        r'('\n",
    "            r'\\b\\d{1,2}[/-]\\d{1,2}[/-]\\d{2,4}\\b|'                            # DD/MM/YYYY, MM-DD-YY, etc.\n",
    "            r'\\b(?:January|February|March|April|May|June|July|August|September|October|November|December)\\s+\\d{1,2},\\s+\\d{4}\\b|'  # Month DD, YYYY\n",
    "            r'\\b\\d{4}[/-]\\d{1,2}[/-]\\d{1,2}\\b'                             # YYYY/MM/DD, YYYY-MM-DD\n",
    "        r')'\n",
    "    )\n",
    "    dates = dates_pattern.findall(text)\n",
    "    return dates\n",
    "\n",
    "def code_extraction(text: str) -> List[str]|str:\n",
    "    from bs4 import BeautifulSoup\n",
    "    soup = BeautifulSoup(text, 'html.parser')\n",
    "    html_code = soup.prettify()\n",
    "    return html_code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
