{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "2. Sistema de clasificación de subreddit. \n",
    "\n",
    "Se deberá implementar una función ```classify_subreddit(text)``` que clasifique un texto de entrada en una de las siguientes \n",
    "categorías: **MachineLearning, datascience, statistics, learnmachinelearning, computerscience, AskStatistics, artificial, analytics, datasets, deeplearning, rstats, computervision, DataScienceJobs, MLQuestions, dataengineering, data, dataanalysis, \n",
    "datascienceproject, Kaggle**.\n",
    "\n",
    "Para ello, se proporciona un dataset sobre el que se podrán entrenar distintos algoritmos\n",
    "de clasificación. La etiqueta del subreddit correspondiente se encuentra en la columna \"subreddit\". Se deberán probar, al menos, los siguientes 3 métodos:\n",
    "- Un método basado en TF-IDF + algoritmo de clasificación de machine learning\n",
    "- Un método basado en entidades reconocidas (Named-Entity Recognition) + algoritmo declasificación de machine learning \n",
    "- Un método basado en Word Embeddings + algoritmo de clasificación de machine learning\n",
    "\n",
    "Para evaluar cada método, se utilizará la métrica f1 score, y se utilizará un 70% de los datos\n",
    "del dataset para entrenamiento y un 30% para test (realizando un sampling aleatorio\n",
    "previo).\"\"\"\n",
    "\n",
    "from IPython.display import Markdown\n",
    "display(Markdown(ejercicio))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los posts de entrenamiento se encuentran en la columna 'clean_post' del dataframe, y las labels en la columna 'subreddit'. Las siguientes son las categorías en las que clasificaremos cada post:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['MachineLearning', 'datascience', 'statistics', 'learnmachinelearning', 'computerscience', 'AskStatistics', 'artificial', 'analytics', 'datasets', 'deeplearning', 'rstats', 'computervision', 'DataScienceJobs', 'MLQuestions', 'dataengineering', 'data', 'dataanalysis', 'datascienceproject', 'Kaggle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "reddit_df = pd.read_csv('processed_dataset.csv', encoding='UTF-8', sep=';', low_memory=False)\n",
    "reddit_df['clean_post'] = reddit_df['clean_post'].fillna('')\n",
    "reddit_df['subreddit'] = reddit_df['subreddit'].fillna('')\n",
    "x_data, y_data = reddit_df['clean_post'], reddit_df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x_data, \n",
    "    y_data,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Método basado en TF-IDF + algoritmo de clasificación de machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Elección del algoritmo de machine learning</h4>\n",
    "\n",
    "Para los métodos de clasificación usaremos regresión logística implementada en la librería sklearn por los siguientes motivos: \n",
    "\n",
    "- Ideal para clasificación binaria/multiclase\n",
    "\n",
    "- Interpretable: Los coeficientes indican importancia de features\n",
    "\n",
    "- Eficiente con datasets grandes\n",
    "\n",
    "- Bueno con datos dispersos (sparse) como text data\n",
    "\n",
    "- Rápido de entrenar y predecir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.5072098375581701\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Features y labels\n",
    "X = reddit_df['clean_post']\n",
    "y = reddit_df['subreddit']\n",
    "\n",
    "# Dividimos con train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Transformamos los datos\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Clasificador\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test_tfidf)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(f'F1 Score: {f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Análisis del F1 score bajo (0.507)</h3>\n",
    "\n",
    "Posibles causas:\n",
    "\n",
    "- Desbalanceo en las clases\n",
    "\n",
    "- Configuración básica de TfidfVectorizer\n",
    "\n",
    "- Parámetros por defecto en Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: {f1}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def train_tfidf_model(df: pd.DataFrame, \n",
    "                      text_column: str = 'clean_post',\n",
    "                      label_column: str = 'subreddit',\n",
    "                      random_state: int = 42) -> tuple:\n",
    "    \"\"\"\n",
    "    Entrena un modelo TF-IDF optimizado para clasificación de texto.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame con los datos\n",
    "        text_column: Nombre de la columna con el texto\n",
    "        label_column: Nombre de la columna con las etiquetas\n",
    "        random_state: Semilla aleatoria\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (modelo entrenado, f1_score)\n",
    "    \"\"\"\n",
    "    # 1. Preparación de datos\n",
    "    # Eliminar textos vacíos y muy cortos\n",
    "    df = df[df[text_column].str.len() > 10].copy()\n",
    "    \n",
    "    # Preparar X e y\n",
    "    X = df[text_column]\n",
    "    y = df[label_column]\n",
    "    \n",
    "    # 2. Split de datos\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y,\n",
    "        test_size=0.3,\n",
    "        random_state=random_state,\n",
    "        stratify=y\n",
    "    )\n",
    "    \n",
    "    # 3. Pipeline con hiperparámetros optimizados\n",
    "    pipeline = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(\n",
    "            max_features=10000,\n",
    "            min_df=2,\n",
    "            max_df=0.95,\n",
    "            ngram_range=(1, 2),\n",
    "            sublinear_tf=True\n",
    "        )),\n",
    "        ('clf', LogisticRegression(\n",
    "            max_iter=1000,\n",
    "            n_jobs=-1,\n",
    "            random_state=random_state\n",
    "        ))\n",
    "    ])\n",
    "    \n",
    "    # 4. Entrenamiento\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # 5. Evaluación\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    return pipeline, f1\n",
    "model,f1 = train_tfidf_model(reddit_df)\n",
    "print('F1 Score: {f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Un método basado en entidades reconocidas (Named-Entity Recognition) + algoritmo declasificación de machine learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from typing import List, Tuple\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Un método basado en Word Embeddings + algoritmo de clasificación de machine learning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mainenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
