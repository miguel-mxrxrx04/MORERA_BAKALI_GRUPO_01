{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "2. Sistema de clasificación de subreddit. \n",
    "\n",
    "Se deberá implementar una función ```classify_subreddit(text)``` que clasifique un texto de entrada en una de las siguientes \n",
    "categorías: **MachineLearning, datascience, statistics, learnmachinelearning, computerscience, AskStatistics, artificial, analytics, datasets, deeplearning, rstats, computervision, DataScienceJobs, MLQuestions, dataengineering, data, dataanalysis, \n",
    "datascienceproject, Kaggle**.\n",
    "\n",
    "Para ello, se proporciona un dataset sobre el que se podrán entrenar distintos algoritmos\n",
    "de clasificación. La etiqueta del subreddit correspondiente se encuentra en la columna \"subreddit\". Se deberán probar, al menos, los siguientes 3 métodos:\n",
    "- Un método basado en TF-IDF + algoritmo de clasificación de machine learning\n",
    "- Un método basado en entidades reconocidas (Named-Entity Recognition) + algoritmo declasificación de machine learning \n",
    "- Un método basado en Word Embeddings + algoritmo de clasificación de machine learning\n",
    "\n",
    "Para evaluar cada método, se utilizará la métrica f1 score, y se utilizará un 70% de los datos\n",
    "del dataset para entrenamiento y un 30% para test (realizando un sampling aleatorio\n",
    "previo).\"\"\"\n",
    "\n",
    "from IPython.display import Markdown\n",
    "display(Markdown(ejercicio))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los posts de entrenamiento se encuentran en la columna 'clean_post' del dataframe, y las labels en la columna 'subreddit'. Las siguientes son las categorías en las que clasificaremos cada post:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['MachineLearning', 'datascience', 'statistics', 'learnmachinelearning', 'computerscience', 'AskStatistics', 'artificial', 'analytics', 'datasets', 'deeplearning', 'rstats', 'computervision', 'DataScienceJobs', 'MLQuestions', 'dataengineering', 'data', 'dataanalysis', 'datascienceproject', 'Kaggle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction import train_test_split\n",
    "\n",
    "df = pd.read_csv('processed_dataset.csv')\n",
    "x_data = df['clean_post']\n",
    "y_data = df['subreddit']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Método basado en TF-IDF + algoritmo de clasificación de machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Elección del algoritmo de machine learning</h4>\n",
    "\n",
    "Para los métodos de clasificación usaremos regresión logística implementada en la librería sklearn por los siguientes motivos: \n",
    "<ul>\n",
    "1. Ideal para clasificación binaria/multiclase\n",
    "\n",
    "2. Interpretable: Los coeficientes indican importancia de features\n",
    "\n",
    "3. Eficiente con datasets grandes\n",
    "\n",
    "4. Bueno con datos dispersos (sparse) como text data\n",
    "\n",
    "5. Rápido de entrenar y predecir\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Define features and labels\n",
    "X = df['clean_post']\n",
    "y = df['subreddit']\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Transform the data\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Initialize and train classifier\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = clf.predict(X_test_tfidf)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(f'F1 Score: {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Un método basado en entidades reconocidas (Named-Entity Recognition) + algoritmo declasificación de machine learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Load spaCy's English model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Function to extract named entity labels\n",
    "def extract_entity_labels(text):\n",
    "    doc = nlp(text)\n",
    "    return ' '.join([ent.label_ for ent in doc.ents])\n",
    "\n",
    "# Extract entity labels from training and testing data\n",
    "X_train_entities = X_train.apply(extract_entity_labels)\n",
    "X_test_entities = X_test.apply(extract_entity_labels)\n",
    "\n",
    "# Initialize CountVectorizer\n",
    "vectorizer_entities = CountVectorizer()\n",
    "\n",
    "# Transform the entity labels\n",
    "X_train_entities_vectorized = vectorizer_entities.fit_transform(X_train_entities)\n",
    "X_test_entities_vectorized = vectorizer_entities.transform(X_test_entities)\n",
    "\n",
    "# Initialize and train classifier\n",
    "clf_entities = LogisticRegression(max_iter=1000)\n",
    "clf_entities.fit(X_train_entities_vectorized, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_entities = clf_entities.predict(X_test_entities_vectorized)\n",
    "f1_entities = f1_score(y_test, y_pred_entities, average='weighted')\n",
    "print(f'F1 Score (NER-based): {f1_entities}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Un método basado en Word Embeddings + algoritmo de clasificación de machine learning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mainenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
