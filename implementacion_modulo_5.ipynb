{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generación de resúmenes.  Implementa  un  método  de  resumen  extractivo  de  posts basado  en  frecuencias  y  evalúa  el  resultado.  \n",
    "\n",
    "Deberás  realizar  distintas  pruebas  para \n",
    "demostrar  que  el  método  es  adecuado  para  el  tipo  de  textos,  realizando  los  ajustes \n",
    "necesarios  para  su  correcto  funcionamiento.  \n",
    "\n",
    "La  función  se  denominará \n",
    "post_summarisation(text: str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Método de resumen extractivo basado en frecuencias\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En caso de que nos centremos en el 'clean_post', conformado por lemmas tokenizados sin posibilidad de legibilidad "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def post_summarisation(text: str):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resumen extractivo en 'post' original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from string import punctuation\n",
    "\n",
    "\n",
    "def post_summarisation(text: str, top_n: int = 3) -> str:\n",
    "    \"\"\"\n",
    "    Genera un resumen extractivo de un texto (post) seleccionando las oraciones\n",
    "    con mayor puntuación basada en la frecuencia de las palabras.\n",
    "    \n",
    "    Parámetros\n",
    "    ----------\n",
    "    text : str\n",
    "        El texto completo del cual se desea generar el resumen.\n",
    "    top_n : int, opcional\n",
    "        Número de oraciones que se desea incluir en el resumen (por defecto 3).\n",
    "    \n",
    "    Retorna\n",
    "    -------\n",
    "    str\n",
    "        Cadenas de oraciones elegidas como resumen (separadas por salto de línea).\n",
    "    \n",
    "    Ejemplo\n",
    "    -------\n",
    "    >>> texto = \\\"\\\"\\\"Este es un ejemplo de texto. Incluye varias oraciones para\n",
    "    ... demostrar cómo se realiza el resumen. El resumen debe reflejar\n",
    "    ... las ideas principales del texto. Este texto habla sobre\n",
    "    ... la importancia de las frecuencias de palabras en el resumen.\\\"\\\"\\\"\n",
    "    >>> resumen = post_summarisation(texto, top_n=2)\n",
    "    >>> print(resumen)\n",
    "    \"\"\"\n",
    "    # 3. Calcular la frecuencia de cada palabra\n",
    "    freq_table = {}\n",
    "    for word in text:\n",
    "        freq_table[word] = freq_table.get(word, 0) + 1\n",
    "\n",
    "    # 4. Puntuar cada oración en base a la frecuencia de sus palabras\n",
    "    sentence_scores = {}\n",
    "    for sentence in sentences:\n",
    "        # Tokenizar la oración (sin puntuaciones, en minúsculas)\n",
    "        sentence_words = [w.lower() for w in word_tokenize(sentence) if w not in punctuation]\n",
    "        \n",
    "        # Calcular la suma de frecuencias\n",
    "        score = 0\n",
    "        for word in sentence_words:\n",
    "            score += freq_table.get(word, 0)\n",
    "        \n",
    "        # Guardar la puntuación (normalizamos por longitud para no favorecer oraciones muy largas)\n",
    "        # (Opcional) Ajuste: dividir la suma total entre la cantidad de palabras\n",
    "        if len(sentence_words) > 0:\n",
    "            sentence_scores[sentence] = score / len(sentence_words)\n",
    "\n",
    "    # 5. Seleccionar las oraciones con la puntuación más alta\n",
    "    # Ordenamos el diccionario de oraciones por valor (puntuación), de mayor a menor\n",
    "    sorted_sentences = sorted(sentence_scores, key=sentence_scores.get, reverse=True)\n",
    "\n",
    "    # Nos quedamos con las 'top_n' oraciones\n",
    "    summary_sentences = sorted_sentences[:top_n]\n",
    "\n",
    "    # 6. (Opcional) Ordenar las oraciones seleccionadas según su aparición en el texto original\n",
    "    # para que el resumen mantenga cierta coherencia.\n",
    "    # Lo haremos comparando índices en la lista original 'sentences'.\n",
    "    summary_sentences_sorted_by_position = sorted(summary_sentences, key=lambda s: sentences.index(s))\n",
    "\n",
    "    # 7. Unir oraciones en un solo string, separadas por salto de línea o un separador\n",
    "    summary = \"\\n\".join(summary_sentences_sorted_by_position)\n",
    "    return summary\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# PRUEBA / DEMO\n",
    "# ---------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # (Importante: Ejecuta nltk.download('punkt') si no lo has hecho antes)\n",
    "    # Ejemplo rápido\n",
    "    sample_text = \"\"\"Este es un post de ejemplo para demostrar la generación de \n",
    "    un resumen extractivo. El resumen debe capturar las ideas principales de \n",
    "    un texto. Implementar el método de resumen basado en frecuencias es \n",
    "    bastante útil en textos largos, donde se busca extraer las oraciones \n",
    "    más relevantes. Esperamos que esta demostración sea clara y concisa.\"\"\"\n",
    "\n",
    "    summary_result = post_summarisation(sample_text)\n",
    "    print(\"Texto original:\\n\", sample_text)\n",
    "    print(\"\\nResumen (top 2 oraciones):\\n\", summary_result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mainenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
